
## ğŸ§  **About the Project**

This project â€” developed by **Team Tetris** â€” focuses on building a **machine translation system** for Englishâ€“Persian using **classical deep learning approaches**, particularly **RNN-based Seq2Seq models with LSTM and Attention mechanisms**.

Our goal is to explore and implement all major steps of a traditional Neural Machine Translation (NMT) pipeline, including:

* ğŸ§¹ **Data Preprocessing** â€” cleaning, normalizing, and tokenizing parallel corpora for Persian and English.
* ğŸ“ **Linguistic Feature Extraction** â€” applying POS tagging and Named Entity Recognition (NER) to analyze their impact on translation quality.
* ğŸ”¡ **Subword Tokenization & Embedding** â€” using modern subword models (e.g., SentencePiece/BPE) and embedding techniques.
* ğŸ§  **Model Design & Training** â€” implementing a Seq2Seq model with LSTM encoderâ€“decoder and attention, then training it on large-scale parallel datasets such as **TEP** and **MIZAN**.
* ğŸ“Š **Evaluation & Analysis** â€” measuring performance with BLEU, chrF, and TER metrics, and conducting qualitative error analysis.

This repository contains:

* ğŸ§ª Jupyter notebooks for each stage of the pipeline
* ğŸ§° Preprocessing and model training scripts
* ğŸ“ˆ Experiment logs and evaluation results
* ğŸ“„ A detailed project report.
