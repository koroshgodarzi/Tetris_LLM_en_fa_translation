
## 🧠 **About the Project**

This project — developed by **Team Tetris** — focuses on building a **machine translation system** for English–Persian using **classical deep learning approaches**, particularly **RNN-based Seq2Seq models with LSTM and Attention mechanisms**.

Our goal is to explore and implement all major steps of a traditional Neural Machine Translation (NMT) pipeline, including:

* 🧹 **Data Preprocessing** — cleaning, normalizing, and tokenizing parallel corpora for Persian and English.
* 📝 **Linguistic Feature Extraction** — applying POS tagging and Named Entity Recognition (NER) to analyze their impact on translation quality.
* 🔡 **Subword Tokenization & Embedding** — using modern subword models (e.g., SentencePiece/BPE) and embedding techniques.
* 🧠 **Model Design & Training** — implementing a Seq2Seq model with LSTM encoder–decoder and attention, then training it on large-scale parallel datasets such as **TEP** and **MIZAN**.
* 📊 **Evaluation & Analysis** — measuring performance with BLEU, chrF, and TER metrics, and conducting qualitative error analysis.

This repository contains:

* 🧪 Jupyter notebooks for each stage of the pipeline
* 🧰 Preprocessing and model training scripts
* 📈 Experiment logs and evaluation results
* 📄 A detailed project report.
