{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "<h1> SentencePiece </h1>\n",
        "<h4>\n",
        " یک ابزار توکنایزیشن (تقسیم‌بندی متن) بدون نظارت و زبان‌مستقل است که توسط گوگل برای پردازش متن در سیستم‌های شبکه عصبی (مانند ترجمه ماشینی) توسعه یافته است.\n",
        " </h4>\n",
        "</div>"
      ],
      "metadata": {
        "id": "7uPqGQYL_W8B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "<h2>ویژگی‌های کلیدی</h2>\n",
        "\n",
        "<h4>\n",
        "\n",
        "*   زبان‌مستقل: مستقیماً روی جملات خام کار می‌کند، بدون نیاز به ابزارهای پیش‌توکنایزیشن مانند Moses یا MeCab. مناسب برای زبان‌هایی مانند ژاپنی و چینی که فضاهای واضحی بین کلمات ندارند.\n",
        "*   بدون از دست دادن اطلاعات (Lossless): فضاها را با متا-نماد \"▁\" (U+2581) حفظ می‌کند، بنابراین تبدیل متن به توکن و برعکس دقیق است.\n",
        "\n",
        "\n",
        "\n",
        "*   نرمال‌سازی: از نرمال‌سازی NFKC یونیکد استفاده می‌کند و نقشه‌برداری واژگان به ID را مدیریت می‌کند.\n",
        "*   منظم‌سازی زیرواژه: از BPE-dropout و نمونه‌برداری زیرواژه پشتیبانی می‌کند تا مدل‌های شبکه عصبی را مقاوم‌تر کند.\n",
        "</h4>\n",
        "\n",
        "</div>"
      ],
      "metadata": {
        "id": "Ufr98NWC-g8f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "<h2>مدل‌های توکنایزیشن</h2>\n",
        "<h4>\n",
        "SentencePiece از چهار مدل تقسیم‌بندی پشتیبانی می‌کند:\n",
        "\n",
        "* BPE (Byte-Pair-Encoding): جفت‌های پرتکرار کاراکترها یا زیرواژه‌ها را به صورت تکراری ادغام می‌کند تا واژگان به اندازه ثابت برسد. مناسب برای زبان‌های با مورفولوژی پیچیده.\n",
        "* Unigram Language Model: از مدل زبانی احتمالی استفاده می‌کند و با الگوریتم Viterbi بهترین تقسیم‌بندی را پیدا می‌کند. از نمونه‌برداری زیرواژه برای تعمیم‌پذیری بهتر پشتیبانی می‌کند.\n",
        "* Char: متن را به کاراکترهای جداگانه تقسیم می‌کند، مناسب برای زبان‌های با مجموعه کاراکتر کوچک.\n",
        "* Word: متن را به کلمات کامل تقسیم می‌کند، اما نیاز به پیش‌توکنایزیشن دارد و کمتر استفاده می‌شود.\n",
        "</h4>\n",
        "</dir>"
      ],
      "metadata": {
        "id": "klYsFwvbA_30"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "<h2>فرآیندها</h2>\n",
        "\n",
        "آموزش (Training):\n",
        "\n",
        "* ورودی: کورپوس خام (یک جمله در هر خط).\n",
        "پارامترها: اندازه واژگان (مثلاً 8000 یا 32000)، پوشش کاراکتر (معمولاً 0.9995)، نوع مدل (BPE، Unigram و غیره).\n",
        "\n",
        "* خروجی: مدل آموزش‌دیده و فایل واژگان. فرآیند سریع (50 هزار جمله در ثانیه) و کم‌مصرف (6MB حافظه) است.\n",
        "برای BPE، جفت‌های پرتکرار ادغام می‌شوند؛ برای Unigram، از الگوریتم EM برای بهینه‌سازی احتمالات استفاده می‌شود.\n",
        "\n",
        "\n",
        "انکودینگ (Encoding):\n",
        "\n",
        "متن خام به زیرواژه‌ها یا IDها تبدیل می‌شود (مثلاً \"Hello world.\" به \"▁Hello ▁world .\").\n",
        "از نمونه‌برداری تصادفی (با پارامترهایی مانند --nbest_size و --alpha) برای بهبود استحکام پشتیبانی می‌کند.\n",
        "\n",
        "\n",
        "دیکودینگ (Decoding):\n",
        "\n",
        "توکن‌ها یا IDها را به متن خام برمی‌گرداند، با حذف \"▁\" برای بازسازی فضاها.\n",
        "</dir>"
      ],
      "metadata": {
        "id": "02KPZuWeBgdV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "<h2>مزایا</h2>\n",
        "<h3>\n",
        "\n",
        "* سرعت و کارایی: آموزش و پردازش سریع با مصرف حافظه کم.\n",
        "انعطاف‌پذیری: برای زبان‌های متنوع و مدل‌های NLP مانند BERT و T5 مناسب است.\n",
        "\n",
        " * استحکام: منظم‌سازی زیرواژه باعث بهبود عملکرد مدل‌ها در داده‌های نادیده‌شده می‌شود.\n",
        "\n",
        "* زبان‌مستقل: بدون نیاز به پیش‌پردازش، برای زبان‌های کم‌منبع و چندزبانه ایده‌آل است.\n",
        "</h3>"
      ],
      "metadata": {
        "id": "nFI57ZSsCBnJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "<h2>کاربردها</h2>\n",
        "<h4>\n",
        "SentencePiece در سیستم‌های ترجمه ماشینی عصبی، مدل‌های زبانی (مانند BERT، T5) و پردازش متن چندزبانه استفاده می‌شود. با کاهش اندازه واژگان و مدیریت کلمات نادر، عملکرد مدل‌های NLP را بهبود می‌بخشد.\n",
        "</h4>\n",
        "</div>"
      ],
      "metadata": {
        "id": "Wg28Tz2ODqRk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "<h2>\n",
        "مثال عملی"
      ],
      "metadata": {
        "id": "lDxZ8JgqKaGZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0u7o9Nc-QjX"
      },
      "outputs": [],
      "source": [
        "import sentencepiece as spm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"corpus.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        print(line.strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0olfhdRUHna-",
        "outputId": "630db04f-e129-4444-8944-cf85cd146d95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab_size تعداد واحدهای واژگان (tokens یا subwords) را مشخص می‌کند،\n",
            "الگوریتم‌های توکن‌سازی زیرکلمه‌ (Subword tokenization) بر این اصل تکیه می‌کنند که کلمات پرکاربرد نباید به زیرکلمه‌های کوچک‌تر تقسیم شوند، بلکه کلمات نادر باید به زیرکلمه‌های معنادار تجزیه شوند.\n",
            "من علی زالی هستم.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spm.SentencePieceTrainer.train(\n",
        "    input='corpus.txt',\n",
        "    model_prefix='persian_tokeniza',\n",
        "    vocab_size=285,  # 55 to 512\n",
        "    model_type='BPE',  # BPE, Unigram, char, word\n",
        "    character_coverage=1.0,\n",
        "    max_sentence_length=10000\n",
        ")"
      ],
      "metadata": {
        "id": "JajX6WG2GBBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sp = spm.SentencePieceProcessor()\n",
        "sp.load('persian_tokeniza.model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zW2odYfqIpru",
        "outputId": "06467e3a-a367-47d7-f53c-e2220340c15c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"برای اینکه SentencePiece تست شود توسط علی زالی این جمله نوشته شده.\"\n",
        "encoded_pieces = sp.encode_as_pieces(sentence)\n",
        "encoded_ids = sp.encode_as_ids(sentence)"
      ],
      "metadata": {
        "id": "tIgG2wuxJBWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_pieces"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdQWXQi8JXwr",
        "outputId": "791d3519-fe3d-4551-db4f-1e064deb88f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['▁بر',\n",
              " 'ای',\n",
              " '▁این',\n",
              " 'که',\n",
              " '▁',\n",
              " 'S',\n",
              " 'en',\n",
              " 't',\n",
              " 'en',\n",
              " 'c',\n",
              " 'e',\n",
              " 'P',\n",
              " 'i',\n",
              " 'e',\n",
              " 'c',\n",
              " 'e',\n",
              " '▁ت',\n",
              " 'ست',\n",
              " '▁شو',\n",
              " 'د',\n",
              " '▁ت',\n",
              " 'و',\n",
              " 'س',\n",
              " 'ط',\n",
              " '▁علی',\n",
              " '▁زالی',\n",
              " '▁این',\n",
              " '▁',\n",
              " 'ج',\n",
              " 'م',\n",
              " 'ل',\n",
              " 'ه',\n",
              " '▁ن',\n",
              " 'و',\n",
              " 'ش',\n",
              " 'ت',\n",
              " 'ه',\n",
              " '▁ش',\n",
              " 'ده',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8Gcua21JaTu",
        "outputId": "a10d4015-4848-4177-f467-ebf54efa327f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[91,\n",
              " 3,\n",
              " 110,\n",
              " 205,\n",
              " 237,\n",
              " 274,\n",
              " 20,\n",
              " 257,\n",
              " 20,\n",
              " 276,\n",
              " 254,\n",
              " 0,\n",
              " 255,\n",
              " 254,\n",
              " 276,\n",
              " 254,\n",
              " 4,\n",
              " 181,\n",
              " 37,\n",
              " 243,\n",
              " 4,\n",
              " 249,\n",
              " 258,\n",
              " 0,\n",
              " 111,\n",
              " 120,\n",
              " 110,\n",
              " 237,\n",
              " 278,\n",
              " 242,\n",
              " 247,\n",
              " 240,\n",
              " 31,\n",
              " 249,\n",
              " 259,\n",
              " 246,\n",
              " 240,\n",
              " 218,\n",
              " 177,\n",
              " 263]"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"جمله ورودی:\", sentence)\n",
        "print(\"زیرواژه‌ها:\", encoded_pieces)\n",
        "print(\"ای‌دی‌ها:\", encoded_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvxNVs2tJkCK",
        "outputId": "2356e2d2-2130-4902-a16c-61033e182c21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "جمله ورودی: برای اینکه SentencePiece تست شود توسط علی زالی این جمله نوشته شده.\n",
            "زیرواژه‌ها: ['▁بر', 'ای', '▁این', 'که', '▁', 'S', 'en', 't', 'en', 'c', 'e', 'P', 'i', 'e', 'c', 'e', '▁ت', 'ست', '▁شو', 'د', '▁ت', 'و', 'س', 'ط', '▁علی', '▁زالی', '▁این', '▁', 'ج', 'م', 'ل', 'ه', '▁ن', 'و', 'ش', 'ت', 'ه', '▁ش', 'ده', '.']\n",
            "ای‌دی‌ها: [91, 3, 110, 205, 237, 274, 20, 257, 20, 276, 254, 0, 255, 254, 276, 254, 4, 181, 37, 243, 4, 249, 258, 0, 111, 120, 110, 237, 278, 242, 247, 240, 31, 249, 259, 246, 240, 218, 177, 263]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_sentence = sp.decode_pieces(encoded_pieces)"
      ],
      "metadata": {
        "id": "ct2loqtAJtj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3GM0ZtKpJ_yv",
        "outputId": "f2542c4e-6623-4a1a-ecfe-ebcb52d956e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'برای اینکه SentencePiece تست شود توسط علی زالی این جمله نوشته شده.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O-mSvTFNPs2U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}